{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d398e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree for the dataset using ID3 algorithm is\n",
      " Outlook\n",
      "  Sunny\n",
      "   Humidity\n",
      "    Normal\n",
      "     Yes\n",
      "    High\n",
      "     No\n",
      "  Rain\n",
      "   Wind\n",
      "    Weak\n",
      "     Yes\n",
      "    Strong\n",
      "     No\n",
      "  Overcast\n",
      "   Yes\n",
      "The test instance: ['Overcast', 'Hot', 'Normal', 'Weak']\n",
      "The label for test instance: Yes\n",
      "The test instance: ['Sunny', 'Cool', 'High', 'Strong']\n",
      "The label for test instance: No\n",
      "The test instance: ['Overcast', 'Hot', 'High', 'Weak']\n",
      "The label for test instance: Yes\n",
      "The test instance: ['Rain', 'Mild', 'High', 'Strong']\n",
      "The label for test instance: No\n",
      "The test instance: ['Rain', 'Cool', 'Normal', 'Weak']\n",
      "The label for test instance: Yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import csv\n",
    "\n",
    "def load_csv(filename):\n",
    "    lines=csv.reader(open(filename,\"r\"))\n",
    "    dataset = list(lines)\n",
    "    headers = dataset.pop(0)\n",
    "    return dataset,headers\n",
    "\n",
    "class Node:\n",
    "    def __init__ (self,attribute):\n",
    "        self.attribute=attribute\n",
    "        self.children=[]\n",
    "        self.answer=\"\"\n",
    "\n",
    "\n",
    "def subtables(data,col,delete):  #col is basically a column header\n",
    "    dic={}\n",
    "    coldata=[row[col] for row in data]\n",
    "    \n",
    "    attr=list(set(coldata))  #set returns only unique values in coldata\n",
    "    counts=[0]*len(attr)     #create empty list for every unique value\n",
    "    r=len(data)     #no of rows\n",
    "    c=len(data[0])  #no of columns in each row\n",
    "    for x in range(len(attr)):   #no of unique values in the \"col\" column \n",
    "        for y in range(r):\n",
    "            if data[y][col]==attr[x]:\n",
    "                counts[x]+=1    \n",
    "    for x in range(len(attr)):\n",
    "        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])] #initialing the dictionary items\n",
    "        pos=0\n",
    "        for y in range(r):\n",
    "            if data[y][col]==attr[x]:\n",
    "                if delete:\n",
    "                    del data[y][col]   #removing tat particular column (upper in the tree/parent)\n",
    "                dic[attr[x]][pos]=data[y] #all rows for each unique value\n",
    "                pos+=1\n",
    "    return attr,dic   #attr is a list, dic is a set\n",
    "\n",
    "def entropy(S):\n",
    "    attr=list(set(S))  #S will basically have last column data(not necessarily of all rows)\n",
    "    if len(attr)==1:\n",
    "        return 0    #if there is either only yes/ only no =>entrop is 0\n",
    "    counts=[0,0]\n",
    "    for i in range(2):\n",
    "        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0) #find no of yes and no of no\n",
    "    sums=0\n",
    "    for cnt in counts:\n",
    "        sums+=-1*cnt*math.log(cnt,2)  #base 2(second parameter)\n",
    "    return sums\n",
    "\n",
    "def compute_gain(data,col): #col  is column-header\n",
    "    attr,dic = subtables(data,col,delete=False) #here no deletion, we just calculate gain\n",
    "    total_size=len(data)  # |S| value in formula\n",
    "    entropies=[0]*len(attr) #entropies of each value\n",
    "    ratio=[0]*len(attr)   # to maintain |Sv|/|S| values\n",
    "    total_entropy=entropy([row[-1] for row in data])\n",
    "    \n",
    "    for x in range(len(attr)):\n",
    "        ratio[x]=len(dic[attr[x]])/(total_size*1.0) #len of dic=> |Sv| value\n",
    "        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n",
    "\n",
    "        total_entropy-=ratio[x]*entropies[x] #acc to formula\n",
    "    return total_entropy\n",
    "\n",
    "def build_tree(data,features):\n",
    "    lastcol=[row[-1] for row in data]\n",
    "    if(len(set(lastcol)))==1:  #if last column contains either only \"yes\" or only \"no\"\n",
    "        node=Node(\"\")          #we are not building the tree further(so no attribute)\n",
    "        node.answer=lastcol[0] #it'll be either yes/no\n",
    "        return node\n",
    "    n=len(data[0])-1   #-1 boz we dont need the last column values\n",
    "    gains=[0]*n        # gain is initialized to be 0 for all attributes\n",
    "    for col in range(n):   \n",
    "        gains[col]=compute_gain(data,col)  #compute gain of each attribute\n",
    "    \n",
    "    split=gains.index(max(gains))          # split will have the index of attribute with \"highest gain\"\n",
    "    node=Node(features[split])             # features list will have attribute headings(col names)\n",
    "                                           # so now we create a subtree (node) with that particular attribute\n",
    "    fea = features[:split]+features[split+1:] \n",
    "    attr,dic=subtables(data,split,delete=True)  #attr will have possible values for tat particular attribute\n",
    "                                                #dic will have all rows for all those attributes(key: values)\n",
    "    for x in range(len(attr)):                  \n",
    "        child=build_tree(dic[attr[x]],fea)     #for each value of the attribute\n",
    "        node.children.append((attr[x],child))  #again build the tree (but fea exclude the one already taken)\n",
    "    return node\n",
    "\n",
    "def print_tree(node,level):\n",
    "    if node.answer!=\"\":              #if its a leaf node\n",
    "        print(\" \"*level,node.answer) #just print \"level\" no of spaces, followed by answer (yes/no)\n",
    "        return\n",
    "    print(\" \"*level,node.attribute)  #attribute in the node\n",
    "    for value,n in node.children:\n",
    "        print(\" \"*(level+1),value)\n",
    "        print_tree(n,level+2)        # recursive call to the next node (child)\n",
    "\n",
    "def classify(node,x_test,features): #features: column headers\n",
    "    if node.answer!=\"\":      #this will be true only for leaf nodes(answer: yes/no)\n",
    "        print(node.answer)\n",
    "        return\n",
    "    pos=features.index(node.attribute) #node.attribute will have the col header\n",
    "    for value, n in node.children:   #for every value of that attribute\n",
    "        if x_test[pos]==value:       # for that particular value go along that value\n",
    "            classify(n,x_test,features) #go deeper in the tree\n",
    "\n",
    "\n",
    "dataset,features=load_csv(\"traintennis.csv\")\n",
    "#lastcol=[row[-1] for row in dataset]\n",
    "node1=build_tree(dataset,features)\n",
    "print(\"The decision tree for the dataset using ID3 algorithm is\")\n",
    "print_tree(node1,0)\n",
    "\n",
    "testdata,features=load_csv(\"testtennis.csv\")\n",
    "for xtest in testdata:   #xtest is each row in testdata\n",
    "    print(\"The test instance:\",xtest)\n",
    "    print(\"The label for test instance:\",end=\" \")\n",
    "    classify(node1,xtest,features)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db4444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
